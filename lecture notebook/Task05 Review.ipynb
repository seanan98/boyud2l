{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 卷积神经网络基础\n",
    "\n",
    "## 二维卷积层\n",
    "\n",
    "### 二维互相关运算\n",
    "\n",
    "cross-correlation:\n",
    "\n",
    "![](https://cdn.kesci.com/upload/image/q5nfdbhcw5.png?imageView2/0/w/640/h/640)\n",
    "\n",
    "二维核数组在二维输入数组上滑动，输出也是一个二维输出数组。\n",
    "\n",
    "### 二维卷积层\n",
    "\n",
    "二维卷积层将输入核卷积核做互相关运算，并加上一个标量偏置得到输出。卷积核的模型参数：卷积核、偏置系数。\n",
    "\n",
    "### 互相关运算和卷积运算\n",
    "\n",
    "卷积层中使用的运算并不是卷积运算而是互相关运算。我们将核数组上下翻转，左右翻转再和输入数组做互相关运算，就是卷积运算。但是由于卷积核是可以学习的，所以二者并无本质区别。\n",
    "\n",
    "### 特征图与感受野\n",
    "\n",
    "二维卷积层输出的二维数组可以看作输入再空间维度上某一级的表征，也叫特征图。\n",
    "\n",
    "影响元素x的前向运算的所有可能输入区域叫做x的感受野。\n",
    "\n",
    "## 填充和步幅\n",
    "\n",
    "### 填充\n",
    "\n",
    "padding:在高和宽两侧填充元素（通常是0）\n",
    "\n",
    "如果原输入的高和宽是$n_h$和$n_w$，卷积核的高和宽是$k_h$和$k_w$，在高的两侧**一共填充$p_h$**行，在宽的两侧一共填充$p_w$列，则输出形状为：\n",
    "\n",
    "\n",
    "$$\n",
    "(n_h+p_h-k_h+1)\\times(n_w+p_w-k_w+1)\n",
    "$$\n",
    "\n",
    "\n",
    "我们在卷积神经网络中使用奇数高宽的核，比如$3 \\times 3$，$5 \\times 5$的卷积核，对于高度（或宽度）为大小为$2 k + 1$的核，令步幅为1，在高（或宽）两侧选择大小为$k$的填充，便可保持输入与输出尺寸相同。\n",
    "\n",
    "### 步幅\n",
    "\n",
    "stride:每次滑动的行数和列数。\n",
    "\n",
    "$$\n",
    "\\lfloor(n_h+p_h-k_h+s_h)/s_h\\rfloor \\times \\lfloor(n_w+p_w-k_w+s_w)/s_w\\rfloor\n",
    "$$\n",
    "\n",
    "\n",
    "如果$p_h=k_h-1$，$p_w=k_w-1$，那么输出形状将简化为\n",
    "\n",
    "$\\lfloor(n_h+s_h-1)/s_h\\rfloor \\times \\lfloor(n_w+s_w-1)/s_w\\rfloor$。\n",
    "\n",
    "更进一步，如果输入的高和宽能分别被高和宽上的步幅整除，那么输出形状将是\n",
    "\n",
    "$(n_h / s_h) \\times (n_w/s_w)$。\n",
    "\n",
    "当$p_h = p_w = p$时，我们称填充为$p$；当$s_h = s_w = s$时，我们称步幅为$s$。\n",
    "\n",
    "## 多输入通道和多输出通道\n",
    "\n",
    "### 多输入通道\n",
    "\n",
    "数据在高和宽维度之外，还有其他维度。\n",
    "\n",
    "![](https://cdn.kesci.com/upload/image/q5nfmdnwbq.png?imageView2/0/w/640/h/640)\n",
    "\n",
    "假设输入数据的通道数为$c_i$，卷积核形状为$k_h\\times k_w$，我们为每个输入通道各分配一个形状为$k_h\\times k_w$的核数组，将$c_i$个互相关运算的二维输出按通道相加，得到一个二维数组作为输出。我们把$c_i$个核数组在通道维上连结，即得到一个形状为$c_i\\times k_h\\times k_w$的卷积核。\n",
    "\n",
    "### 多输出通道\n",
    "\n",
    "卷积层的输出也可以包含多个通道，设卷积核输入通道数和输出通道数分别为$c_i$和$c_o$，高和宽分别为$k_h$和$k_w$。如果希望得到含多个通道的输出，我们可以为每个输出通道分别创建形状为$c_i\\times k_h\\times k_w$的核数组，将它们在输出通道维上连结，卷积核的形状即$c_o\\times c_i\\times k_h\\times k_w$。\n",
    "\n",
    "对于输出通道的卷积核，我们提供这样一种理解，一个$c_i \\times k_h \\times k_w$的核数组可以提取某种局部特征，但是输入可能具有相当丰富的特征，我们需要有多个这样的$c_i \\times k_h \\times k_w$的核数组，不同的核数组提取的是不同的特征。\n",
    "\n",
    "### 1×1卷积层\n",
    "\n",
    "![](https://cdn.kesci.com/upload/image/q5nfmq980r.png?imageView2/0/w/640/h/640)\n",
    "\n",
    "1×1卷积核运算前后，输入和输出具有相等的高和宽，但是通道数可能会改变。假设我们将通道维当作特征维，将高和宽维度的元素作为数据样本，那么1×1卷积层的作用与全连接层等价。\n",
    "\n",
    "### 卷积层和全连接层的对比\n",
    "\n",
    "卷积层的两个优势：\n",
    "\n",
    "- 全连接层是将数据展平，输入图像相邻的像素可能因为展平而不再相邻，难以捕获局部信息。卷积神经网络则可以捕捉这种局部信息。\n",
    "\n",
    "- 卷积层参数更少。不考虑偏置的情况下，一个形状为$(c_i, c_o, h, w)$的卷积核的参数量是$c_i \\times c_o \\times h \\times w$，与输入图像的宽高无关。假如一个卷积层的输入和输出形状分别是$(c_1, h_1, w_1)$和$(c_2, h_2, w_2)$，如果要用全连接层进行连接，参数数量就是$c_1 \\times c_2 \\times h_1 \\times w_1 \\times h_2 \\times w_2$。使用卷积层可以以较少的参数数量来处理更大的图像。\n",
    "\n",
    "## 卷积层的简洁实现\n",
    "\n",
    "我们使用Pytorch中的`nn.Conv2d`类来实现二维卷积层，主要关注以下几个构造函数参数：\n",
    "\n",
    "* `in_channels` (python:int) – Number of channels in the input imag\n",
    "* `out_channels` (python:int) – Number of channels produced by the convolution\n",
    "* `kernel_size` (python:int or tuple) – Size of the convolving kernel\n",
    "* `stride` (python:int or tuple, optional) – Stride of the convolution. Default: 1\n",
    "* `padding` (python:int or tuple, optional) – Zero-padding added to both sides of the input. Default: 0\n",
    "* `bias` (bool, optional) – If True, adds a learnable bias to the output. Default: True\n",
    "\n",
    "`forward`函数的参数为一个四维张量，形状为$(N, C_{in}, H_{in}, W_{in})$，返回值也是一个四维张量，形状为$(N, C_{out}, H_{out}, W_{out})$，其中$N$是批量大小，$C, H, W$分别表示通道数、高度、宽度。\n",
    "\n",
    "## 池化\n",
    "\n",
    "### 二维池化层\n",
    "\n",
    "池化层：缓解卷积层对位置的过度敏感性。同卷积层一样，池化层每次对输入数据的一个固定形状的窗口（池化窗口）中的元素计算输出，通常是最大值或者平均值。\n",
    "\n",
    "池化层也有填充和步幅等工作原理。\n",
    "\n",
    "处理多通道数据时，池化层对每个通道分别池化，但是并不会按通道相加，这意味着池化层的输入通道和输出通道数相等。\n",
    "\n",
    "### 池化层的简介实现\n",
    "\n",
    "我们使用Pytorch中的`nn.MaxPool2d`实现最大池化层，关注以下构造函数参数：\n",
    "\n",
    "* `kernel_size` – the size of the window to take a max over\n",
    "* `stride` – the stride of the window. Default value is kernel_size\n",
    "* `padding` – implicit zero padding to be added on both sides\n",
    "\n",
    "`forward`函数的参数为一个四维张量，形状为$(N, C, H_{in}, W_{in})$，返回值也是一个四维张量，形状为$(N, C, H_{out}, W_{out})$，其中$N$是批量大小，$C, H, W$分别表示通道数、高度、宽度。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LeNet\n",
    "\n",
    "## LeNet模型\n",
    "\n",
    "LeNet分为卷积层块和全连接层块两个部分。\n",
    "\n",
    "![](https://tangshusen.me/Dive-into-DL-PyTorch/img/chapter05/5.5_lenet.png)\n",
    "\n",
    "卷积层块的基本单位：卷积层后接最大池化层。卷积层用来识别图像里的空间模式，之后的最大池化层则降低卷积层对位置的敏感性。卷积层块由两个这样的基本单位重复堆叠而成。\n",
    "\n",
    "在卷积层上，使用5×5的卷积核，并在输出上采用sigmoid激活函数。第一个卷积层输出通道为6，第二个卷积层的输出通道则变为16。两个最大池化层的窗口形状均为2×2，且步幅为2，由于池化窗口与步幅形状相同，所以池化窗口并不重叠。\n",
    "\n",
    "卷积层块的输出形状（批量大小，通道，长，宽）。卷积层的输出传入到全连接层时，全连接层会把小批量中每个样本变平，全连接层的输入形状将变为二维，第一维度为小批量大小，第二维度为通道×长×宽。\n",
    "\n",
    "```python\n",
    "import time\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"..\") \n",
    "import d2lzh_pytorch as d2l\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "class LeNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LeNet, self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(1, 6, 5), # in_channels, out_channels, kernel_size\n",
    "            nn.Sigmoid(),\n",
    "            nn.MaxPool2d(2, 2), # kernel_size, stride\n",
    "            nn.Conv2d(6, 16, 5),\n",
    "            nn.Sigmoid(),\n",
    "            nn.MaxPool2d(2, 2)\n",
    "        )\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(16*4*4, 120),\n",
    "            nn.Sigmoid(),\n",
    "            nn.Linear(120, 84),\n",
    "            nn.Sigmoid(),\n",
    "            nn.Linear(84, 10)\n",
    "        )\n",
    "\n",
    "    def forward(self, img):\n",
    "        feature = self.conv(img)\n",
    "        output = self.fc(feature.view(img.shape[0], -1))\n",
    "        return output\n",
    "```\n",
    "\n",
    "## 插曲：如何进行模型构造\n",
    "\n",
    "```python\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    # 声明带有模型参数的层，这里声明了两个全连接层\n",
    "    def __init__(self, **kwargs):\n",
    "        # 调用MLP父类Module的构造函数来进行必要的初始化。这样在构造实例时还可以指定其他函数\n",
    "        # 参数，如“模型参数的访问、初始化和共享”一节将介绍的模型参数params\n",
    "        super(MLP, self).__init__(**kwargs)\n",
    "        self.hidden = nn.Linear(784, 256) # 隐藏层\n",
    "        self.act = nn.ReLU()\n",
    "        self.output = nn.Linear(256, 10)  # 输出层\n",
    "\n",
    "\n",
    "    # 定义模型的前向计算，即如何根据输入x计算返回所需要的模型输出\n",
    "    def forward(self, x):\n",
    "        a = self.act(self.hidden(x))\n",
    "        return self.output(a)\n",
    "```\n",
    "\n",
    "`Module`类是`nn`模块里提供的一个模型构造类，是所有神经网络模块的基类，我们可以继承它来定义我们想要的模型。这里定义的多层感知机`MLP`类重载了`Module`类的`__init__`和`forward`函数，分别用于创建模型参数和定义前向计算。\n",
    "\n",
    "以上的`MLP`类无需定义反向传播函数，系统通过自动求梯度而自动生成反向传播所需的`backward`函数。\n",
    "\n",
    "### `Module`的子类\n",
    "\n",
    "`Module`类是一个通用的部件，Pytorch还实现了继承自`Module`的可以方便构建模型的类：`Sequential`,`ModuleList` and `ModuleDict`。\n",
    "\n",
    "#### `Sequential`类\n",
    "\n",
    "当模型的前向计算为简单的串联各个层的计算时，`Sequential`类可以以更加简单方式定义模型：它可以接收一个子模块的有序字典（OrderdDict）或者一系列子模块作为参数来逐一添加`Module`的实例。\n",
    "\n",
    "下面实现一个与`Sequential`类有相同功能的`MySequential`类。\n",
    "\n",
    "```python\n",
    "class MySequential(nn.Module):\n",
    "    from collections import OrderedDict\n",
    "    def __init__(self, *args):\n",
    "        super(MySequential, self).__init__()\n",
    "        if len(args) == 1 and isinstance(args[0], OrderedDict): # 如果传入的是一个OrderedDict\n",
    "            for key, module in args[0].items():\n",
    "                self.add_module(key, module)  # add_module方法会将module添加进self._modules(一个OrderedDict)\n",
    "        else:  # 传入的是一些Module\n",
    "            for idx, module in enumerate(args):\n",
    "                self.add_module(str(idx), module)\n",
    "    def forward(self, input):\n",
    "        # self._modules返回一个 OrderedDict，保证会按照成员添加时的顺序遍历成员\n",
    "        for module in self._modules.values():\n",
    "            input = module(input)\n",
    "        return input\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ModernCNN\n",
    "## AlexNet\n",
    "\n",
    "首次证明了学习到的特征可以超越⼿⼯设计的特征，从而⼀举打破计算机视觉研究的前状。   \n",
    "**特征：**\n",
    "1. 8层变换，其中有5层卷积和2层全连接隐藏层，以及1个全连接输出层。\n",
    "2. 将sigmoid激活函数改成了更加简单的ReLU激活函数。\n",
    "3. 用Dropout来控制全连接层的模型复杂度。\n",
    "4. 引入数据增强，如翻转、裁剪和颜色变化，从而进一步扩大数据集来缓解过拟合。\n",
    "\n",
    "![](http://tangshusen.me/Dive-into-DL-PyTorch/img/chapter05/5.6_alexnet.png)\n",
    "\n",
    "AlexNet与LeNet的设计理念非常相似，但也有显著的区别。\n",
    "\n",
    "第一，与相对较小的LeNet相比，AlexNet包含8层变换，其中有5层卷积和2层全连接隐藏层，以及1个全连接输出层。下面我们来详细描述这些层的设计。\n",
    "\n",
    "AlexNet第一层中的卷积窗口形状是11×11。因为ImageNet中绝大多数图像的高和宽均比MNIST图像的高和宽大10倍以上，ImageNet图像的物体占用更多的像素，所以需要更大的卷积窗口来捕获物体。第二层中的卷积窗口形状减小到5×5，之后全采用3×3。此外，第一、第二和第五个卷积层之后都使用了窗口形状为3×3、步幅为2的最大池化层。而且，AlexNet使用的卷积通道数也大于LeNet中的卷积通道数数十倍。\n",
    "\n",
    "紧接着最后一个卷积层的是两个输出个数为4096的全连接层。这两个巨大的全连接层带来将近1 GB的模型参数。由于早期显存的限制，最早的AlexNet使用双数据流的设计使一个GPU只需要处理一半模型。幸运的是，显存在过去几年得到了长足的发展，因此通常我们不再需要这样的特别设计了。\n",
    "\n",
    "第二，AlexNet将sigmoid激活函数改成了更加简单的ReLU激活函数。一方面，ReLU激活函数的计算更简单，例如它并没有sigmoid激活函数中的求幂运算。另一方面，ReLU激活函数在不同的参数初始化方法下使模型更容易训练。这是由于当sigmoid激活函数输出极接近0或1时，这些区域的梯度几乎为0，从而造成反向传播无法继续更新部分模型参数；而ReLU激活函数在正区间的梯度恒为1。因此，若模型参数初始化不当，sigmoid函数可能在正区间得到几乎为0的梯度，从而令模型无法得到有效训练。\n",
    "\n",
    "第三，AlexNet通过丢弃法（参见3.13节）来控制全连接层的模型复杂度。而LeNet并没有使用丢弃法。\n",
    "\n",
    "第四，AlexNet引入了大量的图像增广，如翻转、裁剪和颜色变化，从而进一步扩大数据集来缓解过拟合。我们将在后面的9.1节（图像增广）详细介绍这种方法。\n",
    "\n",
    "## 使用重复元素的网络（VGG）\n",
    "\n",
    "重复使用简单的基础快来构造深度模型。\n",
    "\n",
    "![](https://cdn.kesci.com/upload/image/q5l6vut7h1.png?imageView2/0/w/640/h/640)\n",
    "\n",
    "VGG块的组成规律是：连续使用数个相同的填充为1、窗口形状为3×3的卷积层后接上一个步幅为2、窗口形状为2×2的最大池化层。卷积层保持输入的高和宽不变，而池化层则对其减半。我们使用vgg_block函数来实现这个基础的VGG块，它可以指定卷积层的数量和输入输出通道数。\n",
    "\n",
    ">对于给定的感受野（与输出有关的输入图片的局部大小），采用堆积的小卷积核优于采用大的卷积核，因为可以增加网络深度来保证学习更复杂的模式，而且代价还比较小（参数更少）。例如，在VGG中，使用了3个3x3卷积核来代替7x7卷积核，使用了2个3x3卷积核来代替5*5卷积核，这样做的主要目的是在保证具有相同感知野的条件下，提升了网络的深度，在一定程度上提升了神经网络的效果。\n",
    "\n",
    "## NiN（网络中的网络）\n",
    "\n",
    "前几节介绍的LeNet、AlexNet和VGG在设计上的共同之处是：先以由卷积层构成的模块充分抽取空间特征，再以由全连接层构成的模块来输出分类结果。其中，AlexNet和VGG对LeNet的改进主要在于如何对这两个模块加宽（增加通道数）和加深。本节我们介绍网络中的网络（NiN。它提出了另外一个思路，即串联多个由卷积层和“全连接”层构成的小网络来构建一个深层网络。\n",
    "\n",
    "![](https://cdn.kesci.com/upload/image/q5l6u1p5vy.png?imageView2/0/w/960/h/960)\n",
    "\n",
    "### NiN块\n",
    "\n",
    "我们知道，卷积层的输入和输出通常是四维数组（样本，通道，高，宽），而全连接层的输入和输出则通常是二维数组（样本，特征）。如果想在全连接层后再接上卷积层，则需要将全连接层的输出变换为四维。回忆在5.3节（多输入通道和多输出通道）里介绍的1×1卷积层。它可以看成全连接层，其中空间维度（高和宽）上的每个元素相当于样本，通道相当于特征。因此，NiN使用1×1卷积层来替代全连接层，从而使空间信息能够自然传递到后面的层中去。图5.7对比了NiN同AlexNet和VGG等网络在结构上的主要区别。\n",
    "\n",
    "![](https://tangshusen.me/Dive-into-DL-PyTorch/img/chapter05/5.8_nin.svg)\n",
    "<center>左图是LeNet和AlexNet的网络结构局部，右图是NiN的网络结构局部</center>\n",
    "\n",
    "```python\n",
    "def nin_block(in_channels, out_channels, kernel_size, stride, padding):\n",
    "    blk = nn.Sequential(nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding),\n",
    "                        nn.ReLU(),\n",
    "                        nn.Conv2d(out_channels, out_channels, kernel_size=1),\n",
    "                        nn.ReLU(),\n",
    "                        nn.Conv2d(out_channels, out_channels, kernel_size=1),\n",
    "                        nn.ReLU())\n",
    "    return blk\n",
    "```\n",
    " \n",
    "NiN块是NiN中的基础块。它由一个卷积层加两个充当全连接层的1×1卷积层串联而成。其中第一个卷积层的超参数可以自行设置，而第二和第三个卷积层的超参数一般是固定的。\n",
    "\n",
    "NiN是在AlexNet问世不久后提出的。它们的卷积层设定有类似之处。NiN使用卷积窗口形状分别为11×11、5×5和3×3的卷积层，相应的输出通道数也与AlexNet中的一致。每个NiN块后接一个步幅为2、窗口形状为3×3的最大池化层。\n",
    "\n",
    "除使用NiN块以外，NiN还有一个设计与AlexNet显著不同：NiN去掉了AlexNet最后的3个全连接层，取而代之地，NiN使用了输出通道数等于标签类别数的NiN块，然后使用全局平均池化层对每个通道中所有元素求平均并直接用于分类。这里的全局平均池化层即窗口形状等于输入空间维形状的平均池化层。NiN的这个设计的好处是可以显著减小模型参数尺寸，从而缓解过拟合。然而，该设计有时会造成获得有效模型的训练时间的增加。\n",
    "\n",
    "## 含并行连结的网络（GoogLeNet）\n",
    "\n",
    "### Inception块\n",
    "\n",
    "基础卷积块叫做Inception块，得名于同名电影《Inception》。\n",
    "\n",
    "![](https://tangshusen.me/Dive-into-DL-PyTorch/img/chapter05/5.9_inception.svg)\n",
    "\n",
    "<center>Inception块的结构</center>\n",
    "\n",
    "由图5.8可以看出，Inception块里有4条并行的线路。前3条线路使用窗口大小分别是1×1、3×3和5×5的卷积层来抽取不同空间尺寸下的信息，其中中间2个线路会对输入先做1×1卷积来减少输入通道数，以降低模型复杂度。第四条线路则使用3×3最大池化层，后接1×1卷积层来改变通道数。4条线路都使用了合适的填充来使输入与输出的高和宽一致。最后我们将每条线路的输出在通道维上连结，并输入接下来的层中去。\n",
    "\n",
    "```python\n",
    "class Inception(nn.Module):\n",
    "    # c1 - c4为每条线路里的层的输出通道数\n",
    "    def __init__(self, in_c, c1, c2, c3, c4):\n",
    "        super(Inception, self).__init__()\n",
    "        # 线路1，单1 x 1卷积层\n",
    "        self.p1_1 = nn.Conv2d(in_c, c1, kernel_size=1)\n",
    "        # 线路2，1 x 1卷积层后接3 x 3卷积层\n",
    "        self.p2_1 = nn.Conv2d(in_c, c2[0], kernel_size=1)\n",
    "        self.p2_2 = nn.Conv2d(c2[0], c2[1], kernel_size=3, padding=1)\n",
    "        # 线路3，1 x 1卷积层后接5 x 5卷积层\n",
    "        self.p3_1 = nn.Conv2d(in_c, c3[0], kernel_size=1)\n",
    "        self.p3_2 = nn.Conv2d(c3[0], c3[1], kernel_size=5, padding=2)\n",
    "        # 线路4，3 x 3最大池化层后接1 x 1卷积层\n",
    "        self.p4_1 = nn.MaxPool2d(kernel_size=3, stride=1, padding=1)\n",
    "        self.p4_2 = nn.Conv2d(in_c, c4, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        p1 = F.relu(self.p1_1(x))\n",
    "        p2 = F.relu(self.p2_2(F.relu(self.p2_1(x))))\n",
    "        p3 = F.relu(self.p3_2(F.relu(self.p3_1(x))))\n",
    "        p4 = F.relu(self.p4_2(self.p4_1(x)))\n",
    "        return torch.cat((p1, p2, p3, p4), dim=1)  # 在通道维上连结输出\n",
    "```\n",
    "\n",
    "Inception块中可以自定义的超参数是每个层的输出通道数，我们以此来控制模型复杂度。\n",
    "\n",
    "### GoogLeNet模型\n",
    "\n",
    "![](https://cdn.kesci.com/upload/image/q5l6x0fyyn.png?imageView2/0/w/640/h/640)\n",
    "\n",
    "\n",
    "```python\n",
    "\n",
    "b1 = nn.Sequential(nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3),\n",
    "                   nn.ReLU(),\n",
    "                   nn.MaxPool2d(kernel_size=3, stride=2, padding=1))\n",
    "\n",
    "b2 = nn.Sequential(nn.Conv2d(64, 64, kernel_size=1),\n",
    "                   nn.Conv2d(64, 192, kernel_size=3, padding=1),\n",
    "                   nn.MaxPool2d(kernel_size=3, stride=2, padding=1))\n",
    "\n",
    "b3 = nn.Sequential(Inception(192, 64, (96, 128), (16, 32), 32),\n",
    "                   Inception(256, 128, (128, 192), (32, 96), 64),\n",
    "                   nn.MaxPool2d(kernel_size=3, stride=2, padding=1))\n",
    "\n",
    "b4 = nn.Sequential(Inception(480, 192, (96, 208), (16, 48), 64),\n",
    "                   Inception(512, 160, (112, 224), (24, 64), 64),\n",
    "                   Inception(512, 128, (128, 256), (24, 64), 64),\n",
    "                   Inception(512, 112, (144, 288), (32, 64), 64),\n",
    "                   Inception(528, 256, (160, 320), (32, 128), 128),\n",
    "                   nn.MaxPool2d(kernel_size=3, stride=2, padding=1))\n",
    "\n",
    "b5 = nn.Sequential(Inception(832, 256, (160, 320), (32, 128), 128),\n",
    "                   Inception(832, 384, (192, 384), (48, 128), 128),\n",
    "                   d2l.GlobalAvgPool2d())\n",
    "\n",
    "net = nn.Sequential(b1, b2, b3, b4, b5, \n",
    "                    d2l.FlattenLayer(), nn.Linear(1024, 10))\n",
    "\n",
    "net = nn.Sequential(b1, b2, b3, b4, b5, d2l.FlattenLayer(), nn.Linear(1024, 10))\n",
    "\n",
    "X = torch.rand(1, 1, 96, 96)\n",
    "\n",
    "for blk in net.children(): \n",
    "    X = blk(X)\n",
    "    print('output shape: ', X.shape)\n",
    "\n",
    "#batchsize=128\n",
    "batch_size = 16\n",
    "# 如出现“out of memory”的报错信息，可减小batch_size或resize\n",
    "#train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size, resize=96)\n",
    "\n",
    "lr, num_epochs = 0.001, 5\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=lr)\n",
    "d2l.train_ch5(net, train_iter, test_iter, batch_size, optimizer, device, num_epochs)\n",
    "``` "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
